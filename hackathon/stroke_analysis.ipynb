{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = train[\"bmi\"].value_counts()\n",
    "#plt.figure(figsize =(20,10))\n",
    "#c.plot(kind = 'bar')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"work_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(train.gender)):\n",
    "    if train.gender[i] ==\"Male\":\n",
    "        train.gender[i] = 1\n",
    "    elif train.gender[i] ==\"Female\":\n",
    "        train.gender[i] = 0\n",
    "    elif train.gender[i] ==\"Other\":\n",
    "        train.gender[i] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"ever_married\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(train.gender)):\n",
    "    if train.ever_married[i] ==\"Yes\":\n",
    "        train.ever_married[i] = 1\n",
    "    elif train.ever_married[i] ==\"No\":\n",
    "        train.ever_married[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Residence_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(train.Residence_type)):\n",
    "    if train.Residence_type[i] ==\"Urban\":\n",
    "        train.Residence_type[i] = 1\n",
    "    elif train.Residence_type[i] ==\"Rural\":\n",
    "        train.Residence_type[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"gender\"] = pd.to_numeric(train[\"gender\"], errors = \"coerce\") # To return the missing values as NaN untouched\n",
    "train[\"ever_married\"] = pd.to_numeric(train[\"ever_married\"], errors = \"coerce\") # To return the missing values as NaN untouched\n",
    "train[\"Residence_type\"] = pd.to_numeric(train[\"Residence_type\"], errors = \"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns = ['work_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(train.columns.values) #Make a list of all of the columns in the df\n",
    "cols.pop(cols.index('stroke'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[cols+['stroke']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now, coming to the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(test.ever_married)):\n",
    "    if test.ever_married[i] ==\"Yes\":\n",
    "        test.ever_married[i] = 1\n",
    "    elif test.ever_married[i] ==\"No\":\n",
    "        test.ever_married[i] = 0\n",
    "#test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(test.gender)):\n",
    "    if test.gender[i] ==\"Male\":\n",
    "        test.gender[i] = 1\n",
    "    elif test.gender[i] ==\"Female\":\n",
    "        test.gender[i] = 0\n",
    "    elif test.gender[i] ==\"Other\":\n",
    "        test.gender[i] = 2\n",
    "#test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(test.Residence_type)):\n",
    "    if test.Residence_type[i] ==\"Urban\":\n",
    "        test.Residence_type[i] = 1\n",
    "    elif test.Residence_type[i] ==\"Rural\":\n",
    "        test.Residence_type[i] = 0\n",
    "#test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Residence_type\"] = pd.to_numeric(test[\"Residence_type\"], errors = \"coerce\") # To return the missing values as NaN untouched\n",
    "test[\"gender\"] = pd.to_numeric(test[\"gender\"], errors = \"coerce\") # To return the missing values as NaN untouched\n",
    "test[\"ever_married\"] = pd.to_numeric(test[\"ever_married\"], errors = \"coerce\") # To return the missing values as NaN untouched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.get_dummies(test, columns = ['work_type'])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"stroke\"] = \"\"\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([train, test], ignore_index = True)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(\"smoking_status\", 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(axis = 0, inplace = True)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"stroke\"] = pd.to_numeric(dataset[\"stroke\"], errors = \"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X and y allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, [0,1,2,3,4,5,6,7,8,9,10,11,12,13]].values\n",
    "y = dataset.iloc[:, 14].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[0:41938]\n",
    "X_test = X[41938:59949]\n",
    "y_train = y[0:41938]\n",
    "y_test = y[41938:59949]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)+len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)+len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X[0:41938]\n",
    "y1 = y[0:41938]\n",
    "print(len(X1))\n",
    "print(len(y1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN-TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X1_train.shape)\n",
    "print(X1_test.shape)\n",
    "print(y1_train.shape)\n",
    "print(y1_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the classifier in the Training set\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier1 = LogisticRegression(random_state = 0)\n",
    "classifier1.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test Set results\n",
    "y1_pred = classifier1.predict(X1_test)\n",
    "\n",
    "# Confusion matrix for the accuracy\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm1 = confusion_matrix(y1_test, y1_pred)\n",
    "accuracy1 = accuracy_score(y1_test, y1_pred)\n",
    "print(\"\\n The Confusion Matrix is:\", cm)\n",
    "print(\"\\n The accuracy of the model in percentage is:\", accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBOOST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting XGBoost to the training set\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "classifier2 = XGBClassifier(n_jobs = -1)\n",
    "classifier2.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test Set results\n",
    "y1_pred = classifier2.predict(X1_test)\n",
    "\n",
    "# Confusion matrix for the accuracy\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm2 = confusion_matrix(y1_test, y1_pred)\n",
    "accuracy2 = accuracy_score(y1_test, y1_pred)\n",
    "print(\"\\n The Confusion Matrix is:\", cm)\n",
    "print(\"\\n The accuracy of the model in percentage is:\", accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRID SEARCH FOR THE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the classifier in the Training set\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\"C\":[0.75, 0.8, 0.85],\"solver\":['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = parameters, scoring = 'accuracy', cv = 10, n_jobs = -1)\n",
    "grid_search = grid_search.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(best_accuracy*100)\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting XGBoost to the training set\n",
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\"max_depth\":[3,4,5],\"learning_rate\":[0.06, 0.05, 0.04, 0.03]}\n",
    "grid_search = GridSearchCV(estimator = classifier, param_grid = parameters, scoring = 'accuracy', cv = 10, n_jobs = -1)\n",
    "grid_search = grid_search.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(best_accuracy)\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REVISED PARAMETERS MODEL IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the classifier in the Training set\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier1 = LogisticRegression(C = 0.75, solver = 'newton-cg', random_state = 0)\n",
    "classifier1.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test Set results\n",
    "y1_pred = classifier1.predict(X1_test)\n",
    "\n",
    "# Confusion matrix for the accuracy\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm1 = confusion_matrix(y1_test, y1_pred)\n",
    "accuracy1 = accuracy_score(y1_test, y1_pred)\n",
    "print(\"\\n The Confusion Matrix is:\", cm)\n",
    "print(\"\\n The accuracy of the model in percentage is:\", accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting XGBoost to the training set\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "classifier2 = XGBClassifier(max_depth = 3, learning_rate = 0.06, n_jobs = -1)\n",
    "classifier2.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test Set results\n",
    "y1_pred = classifier2.predict(X1_test)\n",
    "\n",
    "# Confusion matrix for the accuracy\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm2 = confusion_matrix(y1_test, y1_pred)\n",
    "accuracy2 = accuracy_score(y1_test, y1_pred)\n",
    "print(\"\\n The Confusion Matrix is:\", cm)\n",
    "print(\"\\n The accuracy of the model in percentage is:\", accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL IMPLEMENTATION FOR TRAIN AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting XGBoost to the training set\n",
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier(learning_rate = 0.06, max_depth= 4, n_jobs = -1)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test Set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Count = Counter(y_pred)\n",
    "Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the classifier in the Training set\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier4 = LogisticRegression(C= 0.75, solver= 'newton-cg', random_state = 0)\n",
    "classifier4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test Set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Count = Counter(y_pred)\n",
    "Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FROM THE ABOVE PREDICTIONS, IT IS SEEN THAT THE PEOPLE IN THE TEST SET WILL NOT HAVE STROKE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
